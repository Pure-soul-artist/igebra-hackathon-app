import { NextResponse } from "next/server";
import { HfInference } from "@huggingface/inference";

// Initialize Hugging Face Inference API
const hf = new HfInference(process.env.HUGGINGFACE_API_KEY);

export async function POST(req) {
  try {
    const { text } = await req.json();

    // Check if the text is provided
    if (!text || text.trim() === "") {
      return NextResponse.json({ error: "No text provided" }, { status: 400 });
    }

    // Use the Hugging Face question answering model
    const response = await hf.questionAnswering({
      model: "deepset/roberta-base-squad2", // Model for question answering
      context: text,
      question: "What are the key points in this text?", // Question for summarization
    });

    // Check if the response has an answer
    if (!response.answer) {
      return NextResponse.json({ error: "No answer generated by the model" }, { status: 500 });
    }

    // Extract the generated answer from Hugging Face response
    const answer = response.answer;

    // Create flashcards from the answer
    const flashcards = [
      {
        question: "What are the key points in this text?",
        answer: answer,
      },
    ];

    // Return the generated flashcards
    return NextResponse.json({ flashcards });
  } catch (error) {
    // Handle any errors
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}
